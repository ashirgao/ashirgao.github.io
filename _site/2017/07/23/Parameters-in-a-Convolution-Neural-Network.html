<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Parameters in a Convolutional Neural Network</title>
  <meta name="description" content="A convolutional neural network (CNN) ! From my experience, the deeper (:P) you study them, the more they amaze you with their capability and awe you with the...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/2017/07/23/Parameters-in-a-Convolution-Neural-Network.html">
  <link rel="alternate" type="application/rss+xml" title="ashirgao.github.io" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">ashirgao.github.io</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
            <a class="page-link" href="/about/">About</a>
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Parameters in a Convolutional Neural Network</h1>
    <p class="post-meta">
      <time datetime="2017-07-23T12:12:12+05:30" itemprop="datePublished">
        
        Jul 23, 2017
      </time>
      </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>A convolutional neural network (CNN) ! From my experience, the deeper (:P) you study them, the more they amaze you with their capability and awe you with their structure (which you thought you already knew).</p>

<p>If you are a beginner and have a cursory knowledge of how a Convolutional Neural Network works, you have hit a jackpot by reaching this page. In this post, I am going in depth through the forward propogation phase in the training of a CNN. I will discuss and calculate the number of parameters in a CNN as well as closely study the shape transformation of the training batch as we propogate through the network.</p>

<p>Understanding this will help you better grasp the working of a CNN and design better models. Note that the following post uses a keras example, but the number of parameter calculation and shape transformation you will learn here is same for all deep learning libraries.</p>

<p>For demonstration purposes let us study the model structure described <a href="https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py">here</a>. Nothing special about that model, just that I don’t have to write a fresh code from the ground up.</p>

<p>I will not be showing the entire code here. I am just showing snippets of code that are relevant to the task we have undertaken.</p>

<p>We will be considering the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a>.
The dataset is made of</p>
<ul>
  <li>50000 training samples</li>
  <li>10000 test samples</li>
</ul>

<p>Each sample contains a RGB image of resolution 32*32 and a label mapping it to one of 10 output classes.</p>

<p>First, let us understand some terms in reference to the keras development environment :</p>

<ul>
  <li>
    <p>A sample - One element in the dataset. eg. A row in a .csv file or dataframe, a image for a CNN, etc.</p>
  </li>
  <li>
    <p>A batch - A batch is a collection of samples of specified length. Instead of updating model parameters after every single sample (online learning), we update them after every batch. We assume that a batch is a better approximation of the dataset than a single sample. Hence, it is better to shuffle your data to get benefits of using batches.</p>
  </li>
  <li>
    <p>An epoch - We say that an epoch is complete when the model has been through the whole dataset.</p>
  </li>
</ul>

<p>So, let us begin.</p>

<p>The shape of a single image depends on the configuration of your keras.
You can find configuration details of your keras installation in a hidden folder in your home directory. You can see its contents by</p>

<pre><code class="language-Shell">$ cat ~/.keras/keras.json
</code></pre>
<div class="highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nt">"image_data_format"</span><span class="p">:</span><span class="w"> </span><span class="s2">"channels_last"</span><span class="p">,</span><span class="w">
    </span><span class="nt">"floatx"</span><span class="p">:</span><span class="w"> </span><span class="s2">"float32"</span><span class="p">,</span><span class="w">
    </span><span class="nt">"epsilon"</span><span class="p">:</span><span class="w"> </span><span class="mi">1e-07</span><span class="p">,</span><span class="w">
    </span><span class="nt">"backend"</span><span class="p">:</span><span class="w"> </span><span class="s2">"tensorflow"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
</div>

<p>Note the folder name is <code class="highlighter-rouge">.keras</code>. This means it is a hidden folder. You can view it in -</p>
<ul>
  <li>Nautilus (File Manager in Ubuntu) by opening it to your home directory and pressing <code class="highlighter-rouge">Ctrl + H</code>.</li>
  <li>In terminal by doing <code class="highlighter-rouge">$ ls -a ~</code></li>
</ul>

<p>If you cannot find <code class="highlighter-rouge">.keras</code> in your home directory you can still view and modify configuration details by entering the following in the python terminal (<a href="https://keras.io/backend/">more</a>)</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">K</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span>	<span class="c">#View</span>
<span class="s">'channels_first'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">K</span><span class="o">.</span><span class="n">set_image_data_format</span><span class="p">(</span><span class="s">'channels_last'</span><span class="p">)</span> <span class="c">#Change</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">K</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span>
<span class="s">'channels_last'</span>
</code></pre>
</div>
<p>You can have image data format as ‘channels_first’ or ‘channels_last’. For this post we will continue with <code class="highlighter-rouge">image_data_format</code> as <code class="highlighter-rouge">'channels_last'</code>. 
So our image has shape <code class="highlighter-rouge">(32,32,3)</code>. The 3 channels correspond to the Red, Green and Blue components of the input image.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">200</span>
</code></pre>
</div>
<p>The batch size here is 32 samples. This means the model parameters will be updated after it sees 32 images. Shape of each batch is <code class="highlighter-rouge">(32,32,32,3)</code>. The first 32 in the tuple represents the batch-size.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># The data, shuffled and split between train and test sets:</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'x_train shape:'</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">'train samples'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">'test samples'</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
</code></pre>
</div>

<p>Our total dataset has shape <code class="highlighter-rouge">(50000, 32, 32, 3)</code>.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># Convert class vectors to binary class matrices.</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</code></pre>
</div>
<p><code class="highlighter-rouge">to_categorical</code> converts a label (which is a integer) into a vector by doing 1-hot-encoding.</p>

<p>ie. 1 becomes [0,1,0,0,0,0,0,0,0,0], 2 becomes [0,0,2,0,0,0,0,0,0,0] and so on.</p>

<p>Read comments in following snippet :</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span><span class="n">input_shape</span><span class="o">=</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span><span class="c"># a.k.a. conv2d_1</span>
<span class="c"># 32 filters(kernels) of shape 3*3 </span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span><span class="c"># a.k.a. conv2d_2</span>
<span class="c"># 32 filters(kernels) of shape 3*3 </span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span> <span class="c"># a.k.a. max_pooling2d_1</span>
<span class="c"># Downsampling </span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">))</span><span class="c"># a.k.a. conv2d_3 </span>
<span class="c"># 64 filters(kernels) of shape 3*3</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span><span class="c"># a.k.a. conv2d_4</span>
<span class="c"># 64 filters(kernels) of shape 3*3 </span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="c"># Downsampling </span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">'softmax'</span><span class="p">))</span>

<span class="c"># initiate RMSprop optimizer</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">rmsprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>

<span class="c"># Let's train the model using RMSprop</span>
<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

</code></pre>
</div>
<p>The above snippet defines the model. Now, let us see the output of <code class="highlighter-rouge">model.summary()</code> .</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      
_________________________________________________________________
activation_2 (Activation)    (None, 30, 30, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 15, 15, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     
_________________________________________________________________
activation_3 (Activation)    (None, 15, 15, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     
_________________________________________________________________
activation_4 (Activation)    (None, 13, 13, 64)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 6, 6, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2304)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               1180160   
_________________________________________________________________
activation_5 (Activation)    (None, 512)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5130      
_________________________________________________________________
activation_6 (Activation)    (None, 10)                0         
=================================================================
Total params: 1,250,858
Trainable params: 1,250,858
Non-trainable params: 0
_________________________________________________________________
</code></pre>
</div>

<p>In the summary, we can see that every output shape has <code class="highlighter-rouge">None</code> in place of the batch-size. This is so as to facilitate changing of batch size at runtime.</p>

<p>Let us now go through each layer (that modifies the shape of the input tensor) in detail studying output shape and number of parameters for each. Shape of the input image is <code class="highlighter-rouge">(None,32,32,3)</code></p>

<ul>
  <li>For <code class="highlighter-rouge">conv2d_1</code> the input shape is <code class="highlighter-rouge">(None,32,32,3)</code> ie our input batch. This layer, as commented in the code snippet earlier, has 32 filters of shape 3 * 3. But in actual the filter isn’t 2D but 3D. The value for the 3rd dimesnion is the number of channels in the previous layers. So the filter shape is infact <code class="highlighter-rouge">(3*3*3)</code>. Here the first 3 * 3 are the filter size and the last 3 being the number of channels in our input ie 3(RGB). Each filter in this layer has a total of 3 * 3 * 3= 27 weight parameters and 1 bias paramter amounting to a total 28 paramters. Also we have 32 such filters. Thus, total there are <code class="highlighter-rouge">(27+1)*32 = 896 paramters</code> in this layer. As we have specified <code class="highlighter-rouge">padding='same'</code> the image shape does not change. So, the output shape is now <code class="highlighter-rouge">(None,32,32,32)</code>. Here the first two 32’s represent the image shape and the third 32 specifies number of channels. <a href="https://keras.io/layers/convolutional/#conv2d">More about Conv2D layer in keras</a>.</li>
</ul>

<p><img src="https://i.stack.imgur.com/T2RWP.png" alt="CNN" />
source:https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-classification-with-deep-convolutional-nn.pdf</p>

<p>The above diagram might help you visualize a CNN. The values and layers in the diagram do not match our example model. But I have still included this diagram for the lack of a better one. As you can see a filter is actually a 3D tensor of weights and each convolution ie. this 3D weight tensor and the input tensor produces a single value in the next layer.</p>

<ul>
  <li>For <code class="highlighter-rouge">conv2d_2</code> the input shape is <code class="highlighter-rouge">(None,32,32,32)</code> ie the output from <code class="highlighter-rouge">activation_1</code> layer. This layer too has 32 filters of shape 3 * 3. Here the actual shape of our filters is <code class="highlighter-rouge">(3*3*32)</code> ie. (3*3) as specified in the model and the 3rd dimension is given by the number of channels in the input 32 (the last 32 in the input shape). Number of parameters per filter is one for weight parameter for every location in the filter ie 3 * 3 * 32 =  288 and an additional 1 bias parameter making the total to 289. Thus, total number of paramters for 32 such filters is <code class="highlighter-rouge">(288+1)*32 = 9248 paramters</code>. Here, we haven’t specified any value for the padding parameter. Thus, it defaults to ‘valid’, ie. no zeros are appended and thus the image size is now (30,30). We again have 32 channels, so the output shape is <code class="highlighter-rouge">(None,30,30,32)</code>. <a href="https://keras.io/layers/convolutional/#conv2d">More about Conv2D layer in keras</a>.</li>
  <li>For <code class="highlighter-rouge">max_pooling2d_1</code> the input shape is <code class="highlighter-rouge">(None,30,30,32)</code>. Here we have specified <code class="highlighter-rouge">pool_size=(2,2)</code>. This means that this layer will reduce a 2 * 2 area of a channel to a single value ie 4 values to 1. But this is not what reduces the size of the tensor. The <code class="highlighter-rouge">MaxPooling2D</code> layer also accepts a paramter called <code class="highlighter-rouge">stride</code> if which not specified defaults to pool_size. Stride is a 2 value tuple that specifies the number of values to move in respective direction before doing a 4-to-1 pool. Thus, in this case the stride is (2,2). Thus our output tensor shape is now <code class="highlighter-rouge">(None,15,15,32)</code>. Note how pooling does not affect the channels.<a href="https://keras.io/layers/pooling/#maxpooling2d">More about MaxPooling2D layer in keras</a>.</li>
</ul>

<p>Similarly for the second block.</p>
<ul>
  <li>
    <p>For <code class="highlighter-rouge">conv2d_3</code> the input shape is <code class="highlighter-rouge">(None,15,15,32)</code> ie the output from <code class="highlighter-rouge">dropout_1</code> layer. This layer 64 filters of shape 3 * 3. We can see in this post and many other cases that the filter size of 3 *3 is very common (VGG16 also uses 3 * 3 filters). The intuition behind choosing them is that the small receptive field digests pattern details better than larger (read sparser) receptive fields.  Here the actual shape of our filters is <code class="highlighter-rouge">(3*3*32)</code> ie. (3 * 3) as specified in the model and the 3rd dimension is given by the number of channels in the input 32 (the last 32 in the input shape). Number of parameters per filter is one for weight parameter for every location in the filter ie 3 * 3 * 32 =  288 and an additional 1 bias parameter making the total to 289. Thus, total number of paramters for 64 such filters is <code class="highlighter-rouge">(288+1)*64 = 18496 paramters</code>. As we have specified <code class="highlighter-rouge">padding='same'</code> the image shape does not change after convolution. So, the output shape is now <code class="highlighter-rouge">(None,15,15,64)</code>. Here the first two 15’s represent the image shape and the third 64 specifies number of channels(number of filters in this layer). <a href="https://keras.io/layers/convolutional/#conv2d">More about Conv2D layer in keras</a>.</p>
  </li>
  <li>For <code class="highlighter-rouge">conv2d_4</code> the input shape is <code class="highlighter-rouge">(None,15,15,64)</code> ie the output from <code class="highlighter-rouge">activation_3</code> layer. This layer too has 64 filters of shape 3 * 3. Here the actual shape of our filters is <code class="highlighter-rouge">(3*3*64)</code> ie. (3*3) as specified in the model and the 3rd dimension is given by the number of channels in the input 64 (the last 64 in the input shape). Number of parameters per filter is one for weight parameter for every location in the filter ie 3 * 3 * 64 =  576 and an additional 1 bias parameter making the total to 577. Thus, total number of paramters for 64 such filters is <code class="highlighter-rouge">(576+1)*64 = 36928 paramters</code>. Here, we haven’t specified any value for the padding parameter. Thus, it defaults to ‘valid’, ie. no zeros are appended and thus the image size is now (13,13). We again have 64 channels, so the output shape is <code class="highlighter-rouge">(None,13,13,64)</code>. <a href="https://keras.io/layers/convolutional/#conv2d">More about Conv2D layer in keras</a>.</li>
  <li>For <code class="highlighter-rouge">max_pooling2d_2</code> the input shape is <code class="highlighter-rouge">(None,13,13,64)</code>. Here we have specified <code class="highlighter-rouge">pool_size=(2,2)</code> and the stride also defaults to (2,2). This means that this layer will reduce a 2 * 2 area of a channel to a single value ie 4 values to 1 in that channel and will repeat this after a taking stride of (2,2) in respective directions. Thus our output tensor shape is now <code class="highlighter-rouge">(None,6,6,64)</code>. Note how pooling does not affect the channels.<a href="https://keras.io/layers/pooling/#maxpooling2d">More about MaxPooling2D layer in keras</a>.</li>
</ul>

<p>Now for the final layers in our model.</p>
<ul>
  <li><code class="highlighter-rouge">flatten_1</code> is a <a href="https://keras.io/layers/core/#flatten">Flatten layer</a>. Input for this layer has shape <code class="highlighter-rouge">(None,6,6,64)</code>. As the name suggests, this layer will flatten the input. The length of the flattened vector will be <code class="highlighter-rouge">6*6*64 = 2304</code>. Thus, the output shape will be <code class="highlighter-rouge">(None,2304)</code>.</li>
  <li><code class="highlighter-rouge">dense_1</code> is a <a href="https://keras.io/layers/core/#dense">Dense layer</a>. This layer has 512 unit. The input has shape <code class="highlighter-rouge">(None,2304)</code>. So, there will be connections from each 2304 units from the Flatten layer to each and every 512 unit in this Dense. Each connection will have a weight parameter. Also each unit will have one bias parameter. So total number of parameters is <code class="highlighter-rouge">2304*512</code> weight parameters  + <code class="highlighter-rouge">512</code> bias parameters  = <code class="highlighter-rouge">1180160</code>. The new output shape is <code class="highlighter-rouge">(None,512)</code>.</li>
  <li>Similarly for <code class="highlighter-rouge">dense_2</code> which has 10 units, we can calculate number of parameters as the sum of number of weight parameters <code class="highlighter-rouge">512*10</code> and bias parameters <code class="highlighter-rouge">10</code> totalling to <code class="highlighter-rouge">5130</code> parameters. Output shape for this layer is <code class="highlighter-rouge">(None,512)</code></li>
</ul>

<p>I hope this post has helped you improve your understanding of Convolution Neural Networks. Let me know what you think in the comments below!</p>


  </div>

    


</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">ashirgao.github.io</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Abhishek Shirgaokar
            
            </li>
            
            <li><a href="mailto:abhishek.shirgaokar at gmail dot com">abhishek.shirgaokar at gmail dot com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/ashirgao"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">ashirgao</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Hey! I&#39;m using this site to document some of my interesting projects. If you  have landed on this page looking for something, I hope you find it and it serves your purpose. Do contact me in case of any corrections in this page, suggestions that can help improve this task and ideas which are related to this task and you find exciting.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
